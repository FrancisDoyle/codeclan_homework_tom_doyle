---
title: "R Notebook"
output: html_notebook
---

1. There are 8 NA values that were imputed:
streetcar suburbs: 208 - 3.6
Tolkien: 416 - 3.58
Patriots: 342 - 3.66
Browns: 49 - 0

2. The average rating was 3.93


3. There were 3667 above average titles and 2974 below average titles

4. Publisher average is 3.92

5. There are 1266 above average publishers and 1026 below average publishers.



--- Libraries

```{r}
library(tidyverse)
library(janitor)
library(dplyr)
```


--- Data Import

```{r}
book_info <- read_csv("data/books.csv")
```



--- Initial View

Dim= (11127,12) NA=8, 4 rows lost id NA's are dropped <-need to investigate 

```{r}
dim(book_info)

view(book_info)

sum(is.na(book_info))

nrow(book_info) - nrow(drop_na(book_info))

colnames(book_info)

```
--- Cleaning

First thing I want to do is locate the NAs then decide what   
is best to do with them

Found simple way to see which columns contain the NAs
(https://sebastiansauer.github.io/sum-isna/)

Looking to see where the NAs are to decide how to deal with them
Either : Impute / replace, drop, or leave alone. 


```{r}
book_info %>% 
  select(everything()) %>%  
  summarise_all(funs(sum(is.na(.)))) # the "." refers to the output of the previous pipe
```

easier way!

```{r}
book_info %>% 
  summarise(across(.fns = ~ sum(is.na(.x))))

book_info %>%  #summarise all = summarise and across
  summarise_all(.funs = ~ sum(is.na(.x)))
```


Checking to see where the NAs are specifically located and they are within 
the same rows for both "average_rating" and "num_pages" 

The data is available on google so will impute:
streetcar suburbs: 208 - 3.6
Tolkien: 416 - 3.58
Patriots: 342 - 3.66
Browns: 49 - 0

```{r}
book_info %>% 
  filter(is.na(num_pages))


books_cleaning <- book_info %>% 
  mutate(num_pages = case_when(
    bookID == "12224" ~ 208, 
    bookID == "16914" ~ 416,
    bookID == "22128" ~ 342,
    bookID == "34889" ~ 49,
    .default = num_pages
  ))

no_na_book_info <- books_cleaning %>% 
  mutate(average_rating = case_when(
    bookID == "12224" ~ 3.6,
    bookID == "16914" ~ 3.58,
    bookID == "22128" ~ 3.66,
    bookID == "34889" ~ 0,
    .default = average_rating
  ))

sum(is.na(no_na_book_info))

```

--- Author Averages

I wanted to see what authors average ratings are.
  
```{r}
author_averages <- no_na_book_info %>%
  group_by(authors) %>% 
    summarise(authors_average = mean(average_rating)) %>%
  arrange(desc(authors_average))

author_averages

```
  
Now I want to check which authors are above/below the overall average.
Pulled the average rating then checked their averages against that.



```{r}
no_na_book_info %>% 
  summarise(mean_rating = mean(average_rating)) %>% 
  pull()
```
```{r}
author_averages %>% 
  mutate(above_average = authors_average >= 3.93) %>% 
  filter(above_average == TRUE)
  

author_averages %>% 
  mutate(above_average = authors_average >= 3.93) %>% 
  filter(above_average == FALSE)

```
  
I want to see th epublisher scores now

```{r}
publisher_averages <- no_na_book_info %>%
  group_by(publisher) %>% 
    summarise(publisher_average = mean(average_rating)) %>%
  arrange(desc(publisher_average))

publisher_averages
```
```{r}
publisher_averages %>% 
  summarise(mean_rating = mean(publisher_average)) %>% 
  pull()
```
```{r}
publisher_averages %>% 
  mutate(above_average = publisher_average >= 3.93) %>% 
  filter(above_average == TRUE)
  

publisher_averages %>% 
  mutate(above_average = publisher_average >= 3.93) %>% 
  filter(above_average == FALSE)
```

# Homework review

1. How many books in each language

```{r}
books_per_language <- book_info %>% 
   group_by(language_code) %>% 
  summarise(num_of_books = n()) %>%  # Number of books in each language
  arrange(desc(num_of_books))

books_per_language

book_info %>% 
  count(language_code) %>% 
 arrange(desc(n))
```


2. Similarities between top rated books

```{r}
book_info %>% 
  filter(ratings_count >= 100) %>% #at least 100 ratings
  slice_max(average_rating, n = 5)
```



3. Do more recently published books receive higher score than older books

```{r}
# We start again with the min1_rating dataset
no_na_book_info %>% 
  select(title, authors, publication_date, average_rating) %>% 
  # lets focus on years only
  mutate(year = format(as.Date(no_na_book_info$publication_date,
                               format="%m/%d/%Y"), "%Y"),
                       .before = publication_date) %>% 
# Let's just create 2 groups, before 2000 is 'old' and younger than 2000 'new'
mutate(age = case_when(
  year <2000 ~ "old",
  year >=2000 ~ "young"
), .after = year) %>% 
 # filter(is.na(year)) # there are 2 books that have NA for year, but publication date is like normal?!
  group_by(age) %>% 
  summarise(average_rating = mean(average_rating))
  
# In conclusion: 'old' books have an average rating of 3.95, 'young' 3.93
# old win!
```


4. Which languages did jk rowling publish books in

```{r}
no_na_book_info %>% 
  select(authors) %>% 
  mutate(jk = str_detect(authors, "J.K. Rowling"), .after = authors) %>% 
  filter(jk == TRUE)

```


5. Misisng vlaues in data



